{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b36e126-df3d-43d6-92ac-b1f932bc2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from TTS.bin.compute_embeddings import compute_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df83a5c-ff16-4b30-a920-6d03aa222a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Computing the speaker embeddings\n",
      "{'output_path': 'checkpoints/', 'logger_uri': None, 'run_name': 'vits_worgen', 'project_name': None, 'run_description': '', 'print_step': 25, 'plot_step': 100, 'model_param_stats': False, 'wandb_entity': None, 'dashboard_logger': 'tensorboard', 'log_model_step': 10000, 'save_step': 30000, 'save_n_checkpoints': 5, 'save_checkpoints': True, 'save_all_best': False, 'save_best_after': 10000, 'target_loss': None, 'print_eval': True, 'test_delay_epochs': -1, 'run_eval': True, 'run_eval_steps': None, 'distributed_backend': 'nccl', 'distributed_url': 'tcp://localhost:54321', 'mixed_precision': False, 'epochs': 1000, 'batch_size': 52, 'eval_batch_size': 52, 'grad_clip': [5.0, 5.0], 'scheduler_after_epoch': True, 'lr': 0.001, 'optimizer': 'AdamW', 'optimizer_params': {'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.01}, 'lr_scheduler': '', 'lr_scheduler_params': None, 'use_grad_scaler': False, 'cudnn_enable': True, 'cudnn_deterministic': False, 'cudnn_benchmark': True, 'training_seed': 54321, 'model': 'vits', 'num_loader_workers': 4, 'num_eval_loader_workers': 4, 'use_noise_augment': False, 'audio': {'fft_size': 1024, 'sample_rate': 16000, 'win_length': 1024, 'hop_length': 256, 'num_mels': 80, 'mel_fmin': 0, 'mel_fmax': None}, 'use_phonemes': False, 'phonemizer': None, 'phoneme_language': 'pt-br', 'compute_input_seq_cache': False, 'text_cleaner': 'multilingual_cleaners', 'enable_eos_bos_chars': False, 'test_sentences_file': '', 'phoneme_cache_path': None, 'characters': {'characters_class': 'TTS.tts.models.vits.VitsCharacters', 'vocab_dict': None, 'pad': '_', 'eos': '&', 'bos': '*', 'blank': None, 'characters': \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz¯·ßàáâãäæçèéêëìíîïñòóôõöùúûüÿāąćēęěīıłńōőœśūűźżǎǐǒǔабвгдежзийклмнопрстуфхцчшщъыьэюяёєіїґ–!'(),-.:;? \", 'punctuations': \"!'(),-.:;? \", 'phonemes': '', 'is_unique': True, 'is_sorted': True}, 'add_blank': True, 'batch_group_size': 0, 'loss_masking': None, 'min_audio_len': 1, 'max_audio_len': inf, 'min_text_len': 1, 'max_text_len': inf, 'compute_f0': False, 'compute_energy': False, 'compute_linear_spec': True, 'precompute_num_workers': 0, 'start_by_longest': False, 'shuffle': False, 'drop_last': False, 'datasets': [{'formatter': 'multi_ljspeech', 'dataset_name': 'worgen', 'path': '../Worgen/', 'meta_file_train': None, 'ignored_speakers': None, 'language': 'en', 'phonemizer': '', 'meta_file_val': None, 'meta_file_attn_mask': ''}], 'test_sentences': [[\"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\", 'VCTK_p277', None, 'en'], ['Be a voice, not an echo.', 'VCTK_p239', None, 'en'], [\"I'm sorry Dave. I'm afraid I can't do that.\", 'VCTK_p258', None, 'en'], [\"This cake is great. It's so delicious and moist.\", 'VCTK_p244', None, 'en'], ['Prior to November 22, 1963.', 'VCTK_p305', None, 'en'], [\"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\", 'female-worgen', None, 'en'], [\"It's only fun when they run!\", 'female-worgen', None, 'en'], ['I am kinder than Miss Alina, though her voice is prettier.', 'female-worgen', None, 'en'], ['My stout ears twitch and swivel, alert for sound. My regal mane billows in the wind, tingling faintly with my braided hair ornaments.', 'female-worgen', None, 'en'], ['I need to move, to do something, anything, even if just jogging in place!', 'female-worgen', None, 'en']], 'eval_split_max_size': None, 'eval_split_size': 0.05, 'use_speaker_weighted_sampler': False, 'speaker_weighted_sampler_alpha': 1.0, 'use_language_weighted_sampler': True, 'language_weighted_sampler_alpha': 1.0, 'use_length_weighted_sampler': False, 'length_weighted_sampler_alpha': 1.0, 'model_args': {'num_chars': 165, 'out_channels': 513, 'spec_segment_size': 62, 'hidden_channels': 192, 'hidden_channels_ffn_text_encoder': 768, 'num_heads_text_encoder': 2, 'num_layers_text_encoder': 10, 'kernel_size_text_encoder': 3, 'dropout_p_text_encoder': 0.1, 'dropout_p_duration_predictor': 0.5, 'kernel_size_posterior_encoder': 5, 'dilation_rate_posterior_encoder': 1, 'num_layers_posterior_encoder': 16, 'kernel_size_flow': 5, 'dilation_rate_flow': 1, 'num_layers_flow': 4, 'resblock_type_decoder': '2', 'resblock_kernel_sizes_decoder': [3, 7, 11], 'resblock_dilation_sizes_decoder': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates_decoder': [8, 8, 2, 2], 'upsample_initial_channel_decoder': 512, 'upsample_kernel_sizes_decoder': [16, 16, 4, 4], 'periods_multi_period_discriminator': [2, 3, 5, 7, 11], 'use_sdp': True, 'noise_scale': 1.0, 'inference_noise_scale': 0.3, 'length_scale': 1.5, 'noise_scale_dp': 0.6, 'inference_noise_scale_dp': 0.3, 'max_inference_len': None, 'init_discriminator': True, 'use_spectral_norm_disriminator': False, 'use_speaker_embedding': False, 'num_speakers': 1244, 'speakers_file': None, 'd_vector_file': 'speakers.pth', 'speaker_embedding_channels': 512, 'use_d_vector_file': True, 'd_vector_dim': 512, 'detach_dp_input': True, 'use_language_embedding': True, 'embedded_language_dim': 4, 'num_languages': 3, 'language_ids_file': None, 'use_speaker_encoder_as_loss': True, 'speaker_encoder_config_path': 'config_se.json', 'speaker_encoder_model_path': 'model_se.pth', 'condition_dp_on_speaker': True, 'freeze_encoder': False, 'freeze_DP': True, 'freeze_PE': True, 'freeze_flow_decoder': True, 'freeze_waveform_decoder': False, 'encoder_sample_rate': None, 'interpolate_z': True, 'reinit_DP': False, 'reinit_text_encoder': False}, 'lr_gen': 0.0002, 'lr_disc': 0.0002, 'lr_scheduler_gen': 'ExponentialLR', 'lr_scheduler_gen_params': {'gamma': 0.999875, 'last_epoch': -1}, 'lr_scheduler_disc': 'ExponentialLR', 'lr_scheduler_disc_params': {'gamma': 0.999875, 'last_epoch': -1}, 'kl_loss_alpha': 1.0, 'disc_loss_alpha': 1.0, 'gen_loss_alpha': 1.0, 'feat_loss_alpha': 1.0, 'mel_loss_alpha': 45.0, 'dur_loss_alpha': 1.0, 'speaker_encoder_loss_alpha': 9.0, 'return_wav': True, 'use_weighted_sampler': False, 'weighted_sampler_attrs': {}, 'weighted_sampler_multipliers': {}, 'r': 1, 'num_speakers': 0, 'use_speaker_embedding': False, 'speakers_file': None, 'speaker_embedding_channels': 256, 'language_ids_file': None, 'use_language_embedding': False, 'use_d_vector_file': True, 'd_vector_file': 'speakers.pth', 'd_vector_dim': 512}\n",
      " | > Found 262 files in C:\\Users\\iambl\\GitHub\\TTS\\recipes\\vctk\\yourtts\\Worgen\n",
      "{'model': 'speaker_encoder', 'run_name': 'speaker_encoder', 'run_description': 'resnet speaker encoder trained with commonvoice all languages dev and train, Voxceleb 1 dev and Voxceleb 2 dev', 'epochs': 100000, 'batch_size': None, 'eval_batch_size': None, 'mixed_precision': False, 'run_eval': True, 'test_delay_epochs': 0, 'print_eval': False, 'print_step': 50, 'tb_plot_step': 100, 'tb_model_param_stats': False, 'save_step': 1000, 'checkpoint': True, 'keep_all_best': False, 'keep_after': 10000, 'num_loader_workers': 8, 'num_val_loader_workers': 0, 'use_noise_augment': False, 'output_path': '../checkpoints/speaker_encoder/language_balanced/normalized/angleproto-4-samples-by-speakers/', 'distributed_backend': 'nccl', 'distributed_url': 'tcp://localhost:54321', 'audio': {'fft_size': 512, 'win_length': 400, 'hop_length': 160, 'frame_shift_ms': None, 'frame_length_ms': None, 'stft_pad_mode': 'reflect', 'sample_rate': 16000, 'resample': False, 'preemphasis': 0.97, 'ref_level_db': 20, 'do_sound_norm': False, 'do_trim_silence': False, 'trim_db': 60, 'power': 1.5, 'griffin_lim_iters': 60, 'num_mels': 64, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'spec_gain': 20, 'signal_norm': False, 'min_level_db': -100, 'symmetric_norm': False, 'max_norm': 4.0, 'clip_norm': False, 'stats_path': None, 'do_rms_norm': True, 'db_level': -27.0}, 'datasets': [{'name': 'voxceleb2', 'path': '/workspace/scratch/ecasanova/datasets/VoxCeleb/vox2_dev_aac/', 'meta_file_train': None, 'ununsed_speakers': None, 'meta_file_val': None, 'meta_file_attn_mask': '', 'language': 'voxceleb'}], 'model_params': {'model_name': 'resnet', 'input_dim': 64, 'use_torch_spec': True, 'log_input': True, 'proj_dim': 512}, 'audio_augmentation': {'p': 0.5, 'rir': {'rir_path': '/workspace/store/ecasanova/ComParE/RIRS_NOISES/simulated_rirs/', 'conv_mode': 'full'}, 'additive': {'sounds_path': '/workspace/store/ecasanova/ComParE/musan/', 'speech': {'min_snr_in_db': 13, 'max_snr_in_db': 20, 'min_num_noises': 1, 'max_num_noises': 1}, 'noise': {'min_snr_in_db': 0, 'max_snr_in_db': 15, 'min_num_noises': 1, 'max_num_noises': 1}, 'music': {'min_snr_in_db': 5, 'max_snr_in_db': 15, 'min_num_noises': 1, 'max_num_noises': 1}}, 'gaussian': {'p': 0.0, 'min_amplitude': 0.0, 'max_amplitude': 1e-05}}, 'storage': {'sample_from_storage_p': 0.5, 'storage_size': 40}, 'max_train_step': 1000000, 'loss': 'angleproto', 'grad_clip': 3.0, 'lr': 0.0001, 'lr_decay': False, 'warmup_steps': 4000, 'wd': 1e-06, 'steps_plot_stats': 100, 'num_speakers_in_batch': 100, 'num_utters_per_speaker': 4, 'skip_speakers': True, 'voice_len': 2.0}\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 262/262 [00:04<00:00, 60.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker embeddings saved at: C:\\Users\\iambl\\GitHub\\TTS\\recipes\\vctk\\yourtts\\WorgenTTS\\speakers.pth\n"
     ]
    }
   ],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "embeddings_file = os.path.join(CURRENT_PATH, \"speakers.pth\")\n",
    "config_file = os.path.join(CURRENT_PATH, \"config.json\")\n",
    "\n",
    "SPEAKER_ENCODER_CHECKPOINT_PATH = r\"C:\\Users\\iambl\\AppData\\Local\\tts\\tts_models--multilingual--multi-dataset--your_tts\\model_se.pth\"\n",
    "SPEAKER_ENCODER_CONFIG_PATH = os.path.join(CURRENT_PATH, \"config_se.json\")\n",
    "\n",
    "print(f\">>> Computing the speaker embeddings\")\n",
    "compute_embeddings(\n",
    "    SPEAKER_ENCODER_CHECKPOINT_PATH,\n",
    "    SPEAKER_ENCODER_CONFIG_PATH,\n",
    "    embeddings_file,\n",
    "    config_dataset_path=config_file,\n",
    "    disable_cuda=False,\n",
    "    no_eval=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc9b1c23-2dac-4e16-b3d3-4addad221c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iambl\\GitHub\\TTS\\recipes\\vctk\\yourtts\\Worgen\\female-worgen\\metadata.txt\n",
      "female-worgen\\metadata.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['female-worgen', 'metadata.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "root_path = os.path.join(os.path.dirname(CURRENT_PATH), \"Worgen\")\n",
    "meta_filename = \"metadata.txt\"\n",
    "meta_files = glob(f\"{root_path}/*/{meta_filename}\", recursive=True)\n",
    "meta_file = meta_files[0]\n",
    "\n",
    "print(meta_file)\n",
    "print(os.path.relpath(meta_file, root_path))\n",
    "\n",
    "os.path.relpath(meta_file, root_path).split(os.sep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttp",
   "language": "python",
   "name": "ttp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
